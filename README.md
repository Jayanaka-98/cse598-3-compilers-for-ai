# CSE 598 (3) Compilers for AI

## Vibe_logs for papers.

| #  | Paper Title | Paper Link | Vibelog |
|:--:|-------------|------------|:-------:|
| 1  | **DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines** | [DSPy](https://arxiv.org/pdf/2310.03714) | [Link](https://chatgpt.com/share/693dc1c1-5b90-800f-bca5-92fdaebb3984) |
| 2  | **GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning** | [GEPA](https://arxiv.org/abs/2507.19457) | [Link](https://github.com/Jayanaka-98/cse598-3-compilers-for-ai/blob/main/gepa.md)|
| 3  | **MTP: A Meaning-Typed Language Abstraction for AI-Integrated Applications** | [MTP](https://arxiv.org/abs/2405.08965) | [Link](https://chatgpt.com/share/693dc847-1afc-800f-906d-4d95f344640a) |
| 4  | **TVM: An Automated End-to-End Optimizing Compiler for Deep Learning** | [TVM](https://arxiv.org/abs/1802.04799) | |
| 5  | **Relay: A High-Level Compiler for Deep Learning** | [Relay](https://arxiv.org/abs/1904.08368) | |
| 6  | **Ansor: Generating High-Performance Tensor Programs for Deep Learning** | [Ansor](https://arxiv.org/abs/2006.06762) | |
| 7 | **PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode and Graph Compilation for DNNs** | [PyTorch 2](https://dl.acm.org/doi/10.1145/3620665.3640366) | |
| 8 | **TorchBench: Benchmarking PyTorch with High API Surface Coverage** | [TorchBench](https://arxiv.org/abs/2304.14226) | |
| 9 | **TorchTitan: One-stop PyTorch Native Solution for Production-Ready LLM Pretraining** | [TorchTitan](https://arxiv.org/abs/2410.06511) | |
| 10 | **ECLIP: Energy-efficient and Practical Co-Location of ML Inference Pipelines on GPUs** | [ECLIP](https://arxiv.org/abs/2506.12598) | |
| 11 | **Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations** | [Triton](https://dl.acm.org/doi/10.1145/3315508.3329973) | |
| 12 | **Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks** | [Geak](https://arxiv.org/abs/2507.23194) | |
| 13 | **Operator Fusion in XLA: Analysis and Evaluation** | [OpFusion](https://arxiv.org/abs/2301.13062) | |
| 14 | **Memory Safe Computations with XLA Compiler** | [MemSafeXLA](https://arxiv.org/abs/2206.14148) | |
| 15 | **MLIR: A Compiler Infrastructure for the End of Moore's Law** | [MLIR](https://arxiv.org/abs/2002.11054) | |
| 16 | **Glow: Graph Lowering Compiler Techniques for Neural Networks** | [Glow](https://arxiv.org/abs/1805.00907) | |
| 17 | **Efficient Memory Management for Large Language Model Serving with PagedAttention** | [PagedAttention](https://arxiv.org/abs/2309.06180) | |
| 18 | **Effective Memory Management for Serving LLMs with Heterogeneity** | [EffLLMServ](https://arxiv.org/abs/2503.18292) | |
| 19 | **Demystifying the NVIDIA Ampere Architecture through Microbenchmarking and Instruction-Level Analysis** | [NVIDIA Ampere](https://arxiv.org/abs/2208.11174) | |
| 20 | **Optimizing sDTW for AMD GPUs** | [AMD sDTW](https://arxiv.org/abs/2403.06931) | |
| 21 | **TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings** | [TPU v4](https://arxiv.org/abs/2304.01433) | |
| 22 | **MTIA: First Generation Silicon Targeting Meta's Recommendation Systems** | [MTIA](https://dl.acm.org/doi/pdf/10.1145/3579371.3589348) | |
| 23 | **Machine Learning Fleet Efficiency: Analyzing and Optimizing Large-Scale Google TPU Systems with ML Productivity Goodput** | [ML Fleet Efficiency](https://arxiv.org/pdf/2502.06982) | |

